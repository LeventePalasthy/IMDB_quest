{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_quest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTR2LRj7ndOq4Wdfjlhd3G"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9uQou9By3Ges"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scrapes the given URL, selects the desired data and returns it in a Pandas DataFrame\n",
        "# Based on: https://www.geeksforgeeks.org/scrape-imdb-movie-rating-and-details-using-python/\n",
        "def scraper():\n",
        "  url = 'http://www.imdb.com/chart/top'\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "  # Selecting the desired data from the site\n",
        "  movies = soup.select('td.titleColumn')\n",
        "  ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')]\n",
        "  number_of_ratings = [c.attrs.get('data-value') for c in soup.select('td.posterColumn span[name=nv]')]\n",
        "\n",
        "  # Building the DataFrame from a list of dictionaries containing the data\n",
        "  list = []\n",
        "  for index in range(20):\n",
        "      movie_string = movies[index].get_text()\n",
        "      movie = (' '.join(movie_string.split()).replace('.', ''))\n",
        "      movie_title = movie[len(str(index))+1:-7]\n",
        "      data = {\"movie_title\": movie_title,\n",
        "              \"rating\": round(float(ratings[index]),1),\n",
        "              \"number_of_ratings\": pd.to_numeric(number_of_ratings[index])\n",
        "              }\n",
        "      list.append(data)\n",
        "  df = pd.DataFrame(list)\n",
        "  return df\n",
        "\n",
        "# Punishes movies for having less ratings\n",
        "# Finds the maximum number of ratings then substracts 0.1 penalty from \n",
        "# each movie per 100k less ratings than the maximum\n",
        "# Input: DataFrame containing information about the movies\n",
        "def review_penalizer(movies):\n",
        "  max = movies['number_of_ratings'].max()\n",
        "  movies['adjusted_rating'] = movies['rating'] - ((max - movies['number_of_ratings'])/100000).apply(np.floor)/10\n",
        "\n",
        "# Sorts and saves the data to a file with a given name and format\n",
        "# Input: DataFrame containing information abouth the movies, the name and format of the output file\n",
        "def save_data(movies, file_name, format):\n",
        "  movies.sort_values(by=['adjusted_rating'],ascending=False,inplace=True)\n",
        "  movies.reset_index(inplace=True, drop=True)\n",
        "  movies['ranking'] = movies.index+1\n",
        "  if format.lower() == 'csv':\n",
        "    movies.to_csv(file_name + '.csv')\n",
        "    return\n",
        "  if format.lower() == 'json':\n",
        "    movies.to_json(file_name + '.json')\n",
        "    return\n",
        "  if format.lower() in ['excel','xls']:\n",
        "    movies.to_excel(file_name + '.xls')\n",
        "    return\n",
        "  print('File format not supported')\n"
      ],
      "metadata": {
        "id": "i_wpnJT8-Vy1"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = scraper()\n",
        "review_penalizer(df)\n",
        "save_data(df,'output','csv')"
      ],
      "metadata": {
        "id": "lvFxylwpZ4H2"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}