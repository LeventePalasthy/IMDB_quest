{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_quest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1/IZe8SjCNfEok6RVRMii"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "9uQou9By3Ges"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scrapes the given URL, selects the desired data and returns it in a Pandas DataFrame\n",
        "# Based on: https://www.geeksforgeeks.org/scrape-imdb-movie-rating-and-details-using-python/\n",
        "def scraper():\n",
        "  url = 'http://www.imdb.com/chart/top'\n",
        "  headers = {'Accept-Language': 'en-US,en;q=0.8'}\n",
        "  response = requests.get(url,headers=headers)\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "  # Selecting the desired data from the site\n",
        "  movies = soup.select('td.titleColumn')\n",
        "  ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')]\n",
        "  number_of_ratings = [c.attrs.get('data-value') for c in soup.select('td.posterColumn span[name=nv]')]\n",
        "\n",
        "  # Getting the indivudual links to each movie to later scrape for number of Oscars\n",
        "  links=[]\n",
        "  oscars = []\n",
        "  for link in soup.find_all('a'):\n",
        "    if '/title/' in str(link):\n",
        "      links.append(link.get('href'))\n",
        "  links=links[1:41:2]\n",
        "\n",
        "  # Building the DataFrame from a list of dictionaries containing the data\n",
        "  _list = []\n",
        "  for index in range(20):\n",
        "      movie_string = movies[index].get_text()\n",
        "      movie = (' '.join(movie_string.split()).replace('.', ''))\n",
        "      movie_title = movie[len(str(index))+1:-7]\n",
        "      \n",
        "      # Scraping each movie's page for the number of Oscars\n",
        "      movie_url = 'http://www.imdb.com' + links[index]\n",
        "      movie_response = requests.get(movie_url)\n",
        "      movie_soup = BeautifulSoup(movie_response.text, \"html.parser\")\n",
        "      for award_string in movie_soup.find_all(class_ = 'ipc-metadata-list-item__label ipc-metadata-list-item__label--link', href=re.compile('\\/title\\/tt[0-9]+\\/awards\\/\\?ref_=tt_awd')):\n",
        "        award = award_string.string.split(' ')\n",
        "        if award[0] == 'Won':\n",
        "          oscars.append(award[1])\n",
        "        else:\n",
        "          oscars.append(0)\n",
        "      \n",
        "      data = {\"movie_title\": movie_title,\n",
        "              \"rating\": round(float(ratings[index]),1),\n",
        "              \"adjusted_rating\": round(float(ratings[index]),1),\n",
        "              \"number_of_ratings\": pd.to_numeric(number_of_ratings[index]),\n",
        "              \"number_of_oscars\": int(oscars[index])\n",
        "              }\n",
        "      _list.append(data)\n",
        "  df = pd.DataFrame(_list)\n",
        "  return df\n",
        "\n",
        "# Punishes movies for having less ratings\n",
        "# Finds the maximum number of ratings then substracts 0.1 penalty from \n",
        "# each movie per 100k less ratings than the maximum\n",
        "# Input: DataFrame containing information about the movies\n",
        "def review_penalizer(movies):\n",
        "  max = movies['number_of_ratings'].max()\n",
        "  movies['adjusted_rating'] = movies['rating'] - ((max - movies['number_of_ratings'])/100000).apply(np.floor)/10\n",
        "  \n",
        "# Gives bonus point to each movie based on the number of Oscars they won\n",
        "# Input: a row of a DataFrame with data about the movie\n",
        "# Returns a row of the DataFrame with the modified rating\n",
        "def oscar_bonus(row):\n",
        "  if row['number_of_oscars'] in [1,2]:\n",
        "    row['adjusted_rating'] += 0.3\n",
        "  elif row['number_of_oscars'] in [3,4,5]:\n",
        "    row['adjusted_rating'] += 0.5\n",
        "  elif row['number_of_oscars'] in [6,7,8,9,10]:\n",
        "    row['adjusted_rating'] += 1\n",
        "  elif row['number_of_oscars'] > 10:\n",
        "    row['adjusted_rating'] += 1.5\n",
        "  return row\n",
        "  \n",
        "# Rewards the movies for having Oscar awards\n",
        "# Input: DataFrame containing information about the movies\n",
        "# Returns the DataFrame with the modified rating\n",
        "def oscar_calculator(movies):\n",
        "  return movies.apply(oscar_bonus,axis=1)\n",
        "\n",
        "# Sorts and saves the data to a file with a given name and format\n",
        "# Supports csv, json and xls formats\n",
        "# Input: DataFrame containing information abouth the movies, the name and format of the output file\n",
        "def save_data(movies, file_name, format):\n",
        "  movies.sort_values(by=['adjusted_rating'],ascending=False,inplace=True)\n",
        "  movies.reset_index(inplace=True, drop=True)\n",
        "  movies['ranking'] = movies.index + 1\n",
        "  if format.lower() == 'csv':\n",
        "    movies.to_csv(file_name + '.csv',index=False)\n",
        "    return\n",
        "  if format.lower() == 'json':\n",
        "    movies.to_json(file_name + '.json')\n",
        "    return\n",
        "  if format.lower() in ['excel','xlsx']:\n",
        "    movies.to_excel(file_name + '.xlsx',index=False)\n",
        "    return\n",
        "  print('File format not supported')"
      ],
      "metadata": {
        "id": "i_wpnJT8-Vy1"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = scraper()\n",
        "review_penalizer(df)\n",
        "df = oscar_calculator(df)\n",
        "save_data(df,'output','csv')"
      ],
      "metadata": {
        "id": "lvFxylwpZ4H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unit Tests"
      ],
      "metadata": {
        "id": "qGIEbU1wzKFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = {\n",
        "    'movie_title': ['A','B','C','D','E'],\n",
        "    'rating': [9.5,9.0,8.7,8.2,5.0],\n",
        "    'adjusted_rating': [9.5,9.0,8.7,8.2,5.0],\n",
        "    'number_of_ratings': [2000000,1900000,2100000,1900001,2099999],\n",
        "    'number_of_oscars': [2,10,0,14,5]\n",
        "\n",
        "}\n",
        "\n",
        "test_df = pd.DataFrame(test_data)\n",
        "review_penalizer(test_df)\n",
        "#test_df\n",
        "assert test_df.at[2,'adjusted_rating'] == 8.7, \"Incorrect result in review_penalizer\"\n",
        "assert test_df.at[3,'adjusted_rating'] == 8.1, \"Incorrect result in review_penalizer\"\n",
        "assert test_df.at[4,'adjusted_rating'] == 5.0, \"Incorrect result in review_penalizer\"\n",
        "print('review_penalizer tests run successfully')\n",
        "\n",
        "\n",
        "test_df = oscar_calculator(test_df)\n",
        "np.testing.assert_almost_equal(test_df.at[0,'adjusted_rating'], 9.7,2, \"Incorrect result in oscar_calculator\")\n",
        "np.testing.assert_almost_equal(test_df.at[1,'adjusted_rating'], 9.8,2, \"Incorrect result in oscar_calculator\")\n",
        "np.testing.assert_almost_equal(test_df.at[4,'adjusted_rating'], 5.5,2, \"Incorrect result in oscar_calculator\")\n",
        "print('oscar_calculator tests run successfully')\n",
        "\n",
        "save_data(test_df,'output','csv')\n",
        "test_df2 = pd.read_csv('output.csv')\n",
        "save_data(test_df2,'output','json')\n",
        "test_df3 = pd.read_json('output.json')\n",
        "save_data(test_df3,'output','excel')\n",
        "test_df4 = pd.read_excel('output.xlsx')\n",
        "try:\n",
        "  pd.testing.assert_frame_equal(test_df,test_df4)\n",
        "  print('save_data tests run successfully')\n",
        "except:\n",
        "  print('Error with save_data')"
      ],
      "metadata": {
        "id": "IP237kHYzLoj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}