{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_quest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO85BWk5yAvA7O+lF8TxW8t"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "9uQou9By3Ges"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scrapes the given URL, selects the desired data and returns it in a Pandas DataFrame\n",
        "# Based on: https://www.geeksforgeeks.org/scrape-imdb-movie-rating-and-details-using-python/\n",
        "def scraper():\n",
        "  url = 'http://www.imdb.com/chart/top'\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "  # Selecting the desired data from the site\n",
        "  movies = soup.select('td.titleColumn')\n",
        "  ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')]\n",
        "  number_of_ratings = [c.attrs.get('data-value') for c in soup.select('td.posterColumn span[name=nv]')]\n",
        "\n",
        "  #Getting the indivudual links to each movie to later scrape for Oscars\n",
        "  links=[]\n",
        "  oscars = []\n",
        "  for link in soup.find_all('a'):\n",
        "    if '/title/' in str(link):\n",
        "      links.append(link.get('href'))\n",
        "  links=links[1:41:2]\n",
        "\n",
        "  # Building the DataFrame from a list of dictionaries containing the data\n",
        "  _list = []\n",
        "  for index in range(20):\n",
        "      movie_string = movies[index].get_text()\n",
        "      movie = (' '.join(movie_string.split()).replace('.', ''))\n",
        "      movie_title = movie[len(str(index))+1:-7]\n",
        "      \n",
        "      # Scareping each movie's page for the number of Oscars\n",
        "      movie_url = 'http://www.imdb.com' + links[index]\n",
        "      movie_response = requests.get(movie_url)\n",
        "      movie_soup = BeautifulSoup(movie_response.text, \"html.parser\")\n",
        "      for award_string in movie_soup.find_all(class_ = 'ipc-metadata-list-item__label ipc-metadata-list-item__label--link', href=re.compile('\\/title\\/tt[0-9]+\\/awards\\/\\?ref_=tt_awd')):\n",
        "        award = award_string.string.split(' ')\n",
        "        if award[0] == 'Won':\n",
        "          oscars.append(award[1])\n",
        "        else:\n",
        "          oscars.append(0)\n",
        "      \n",
        "      data = {\"movie_title\": movie_title,\n",
        "              \"rating\": round(float(ratings[index]),1),\n",
        "              \"number_of_ratings\": pd.to_numeric(number_of_ratings[index]),\n",
        "              \"number_of_oscars\": oscars[index]\n",
        "              }\n",
        "      _list.append(data)\n",
        "  df = pd.DataFrame(_list)\n",
        "  return df\n",
        "\n",
        "# Punishes movies for having less ratings\n",
        "# Finds the maximum number of ratings then substracts 0.1 penalty from \n",
        "# each movie per 100k less ratings than the maximum\n",
        "# Input: DataFrame containing information about the movies\n",
        "def review_penalizer(movies):\n",
        "  max = movies['number_of_ratings'].max()\n",
        "  movies['adjusted_rating'] = movies['rating'] - ((max - movies['number_of_ratings'])/100000).apply(np.floor)/10\n",
        "\n",
        "# Sorts and saves the data to a file with a given name and format\n",
        "# Input: DataFrame containing information abouth the movies, the name and format of the output file\n",
        "def save_data(movies, file_name, format):\n",
        "  movies.sort_values(by=['adjusted_rating'],ascending=False,inplace=True)\n",
        "  movies.reset_index(inplace=True, drop=True)\n",
        "  movies['ranking'] = movies.index+1\n",
        "  if format.lower() == 'csv':\n",
        "    movies.to_csv(file_name + '.csv')\n",
        "    return\n",
        "  if format.lower() == 'json':\n",
        "    movies.to_json(file_name + '.json')\n",
        "    return\n",
        "  if format.lower() in ['excel','xls']:\n",
        "    movies.to_excel(file_name + '.xls')\n",
        "    return\n",
        "  print('File format not supported')"
      ],
      "metadata": {
        "id": "i_wpnJT8-Vy1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = scraper()\n",
        "review_penalizer(df)\n",
        "save_data(df,'output','csv')\n",
        "df"
      ],
      "metadata": {
        "id": "lvFxylwpZ4H2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}